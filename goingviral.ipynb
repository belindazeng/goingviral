{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Popularity: Using Text and Content Analysis to Examine Shared Characteristics of Popular Posts on Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A CS109 Final Project by Belinda Zeng, Roseanne Feng, Yuqi Hou, and Zahra Mahmood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](https://studentshare.net/content/wp-content/uploads/2015/05/53a0e7d640b31_-_unknown-3-51047042.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter (https://twitter.com) is a social network, real-time news media service, and micro-blogging service where users can use text, photos, and videos to express moments or ideas in 140-characters or less. These 140-character messages are called \"tweets.” According to Twitter’s website, millions of tweets are shared in real time, every day. Registered users can read and post tweets, favorite other people’s tweets, retweet other people’s posts, favorite tweets, and follow other accounts. Unregistered users can read tweets from public accounts. \n",
    "\n",
    "In today's day and age of Twitter, popularity is measured in hearts, retweets, follows, and follow-backs. What posts get popular over time? What seems to resonate most with people? Do positive or negative sentiments invite more engagement? In this project, we use Twitter's publically available archive of content to  like to examine some of the shared characteristics of popular posts, including length of post, visual content, positivity, negativity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our idea came from a desire to understand how movements such as #BlackLivesMatter and #Ferguson begin on Twitter as well as a general desire to know what makes a post popular. We chose to focus on Tweets on an individual level and to use natural language processing to be able to understand and predict what makes posts popular.\n",
    "\n",
    "One paper that is related to our work is a paper from Cornell titled, [The effect of wording on message propagation: Topic- and author-controlled natural experiments on Twitter](https://chenhaot.com/pages/wording-for-propagation.html), which compaired pairs of tweets containing the same url and written by the same user but employing different wording to see which version attracted more retweets. Twitter itself has published research on [What fuels a Tweet’s engagement?](https://blog.twitter.com/2014/what-fuels-a-tweets-engagement) Their research found that adding video, links and photos all result in an increase in the number of retweets and even breaking down those results by industry. Inspired by previous research, we sought to include sentiment analysis in our understanding of what made a Tweet popular. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How does the distribution of retweets and hearts vary for a post depending on the time of day when the tweet is created?\n",
    "2. How does positive and negative sentiment affect popularity? \n",
    "3. What Tweets do we think will become popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is publicly available via the Twitter Static API that gets queries based on specific parameters. We limited the data set to look at tweets within a specified period of time. We are storing the data in CSV files for now. To reduce file-sizes, we will try to have multiple CSVs so that we don't load too much data into memory. If data exceeds computer memory, we will consider AWS/SQL database alternatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up oauth and a app on Twitter (to getthe consumer key & secret and access token and secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# great resource where I got all this \n",
    "# http://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/\n",
    "\n",
    "import tweepy\n",
    "import json\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "%run api-keys.py # run any python script and load all of its data directly into the interactive namespace\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial approach is to create a random sample that consists of 1% of tweets. This involves using tweepy and the sample call from the Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "# final, final version \n",
    "\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "# get retweet status\n",
    "def try_retweet(status, attribute):\n",
    "    try:\n",
    "        if getattr(status, attribute):\n",
    "            return True\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "# function that tries to get attribute from object\n",
    "def try_get(status, attribute):\n",
    "    try:\n",
    "        return getattr(status, attribute).encode('utf-8')\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "# open csv file\n",
    "csvFile = open('smallsample.csv', 'a')\n",
    "\n",
    "# create csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "class MyListener(StreamListener):\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        try:\n",
    "            # save relevant components of the tweet\n",
    "            \n",
    "            # get and sanitize hashtags \n",
    "            hashtags = status.entities['hashtags']\n",
    "            hashtag_list = []\n",
    "            for el in hashtags:\n",
    "                hashtag_list.append(el['text'])\n",
    "            hashtag_count = len(hashtag_list)\n",
    "            \n",
    "            # get and sanitize urls\n",
    "            urls = status.entities['urls']\n",
    "            url_list = []\n",
    "            for el in urls:\n",
    "                url_list.append(el['url'])\n",
    "            url_count = len(url_list)\n",
    "            \n",
    "            # get and sanitize user_mentions\n",
    "            user_mentions = status.entities['user_mentions']\n",
    "            mention_list = []\n",
    "            for el in user_mentions:\n",
    "                mention_list.append(el['screen_name'])\n",
    "            mention_count = len(mention_list)\n",
    "            # save it all as a tweet\n",
    "            tweet = [status.created_at, status.text.encode('utf-8'), status.place, status.lang, status.coordinates, \n",
    "              hashtag_list, url_list, mention_list, \n",
    "              hashtag_count, url_count, mention_count, \n",
    "              try_get(status, 'possibly_sensitive'),\n",
    "              status.favorite_count, status.favorited, status.retweet_count, status.retweeted, \n",
    "              try_retweet(status,'retweeted_status'), \n",
    "              try_get(status.user, 'statuses_count'), \n",
    "              try_get(status.user, 'favourites_count'), \n",
    "              try_get(status.user, 'followers_count'),\n",
    "              try_get(status.user, 'description'),\n",
    "              try_get(status.user, 'location')]\n",
    "            \n",
    "            # write to csv\n",
    "            csvWriter.writerow(tweet)\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    "    \n",
    "    # tell us if there's an error\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    "\n",
    "twitter_stream = Stream(auth, MyListener())\n",
    "twitter_stream.sample()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on, analysis will be done on previously scraped tweets, and there is no need to run the above scraping code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweetdf_small=pd.read_csv(\"tempdata/smallsample.csv\", names=[\"created_at\", \"text\", \"place\", \"lang\", \"coordinates\",\n",
    "                                       \"hashtags\", \"urls\", \"user_mentions\", \n",
    "                                       \"hashtag_count\", \"url_count\", \"mention_count\",\n",
    "                                       \"possibly_sensitive\", \n",
    "                                       \"favorite_count\", \"favorited\", \"retweet_count\", \"retweeted\",\n",
    "                                       \"retweeted_status\", \"user_statuses_count\", \"user_favorites_count\",\n",
    "                                       \"user_follower_count\", \"user_description\", \"user_location\"])\n",
    "tweetdf_small.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweetdf_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure there are no missing retweet count\n",
    "tweetdf_missing = tweetdf_small[tweetdf_small['retweet_count'] != 0] \n",
    "tweetdf_missing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the retweet count and favorite count are always 0. This is because we're using the live streaming API and, as a result, we're scraping the tweets as they are tweeted. At this point, all the tweets have retweet count 0 and favorite count 0 since they were literally just posted! That is, unless the tweet posted is actually a retweet... \n",
    "\n",
    "To solve the problem of brand new tweets, we used retweets to get the original tweet. This also ensures that our model isn't thrown off when someone with a huge follower count retweets something. Finally, we made sure not to consider the same tweet text twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Original Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function updates the way we use the tweepy streaming API. We first detect if the tweet we're looking at is actually a retweet of something. If so, we then get the original tweet and save that to our csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "# only save information for retweets\n",
    "\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "# get retweet status\n",
    "def try_retweet(status, attribute):\n",
    "    try:\n",
    "        if getattr(status, attribute):\n",
    "            return True\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "# get country status\n",
    "def try_country(status, attribute):\n",
    "    if getattr(status, attribute) != None:\n",
    "        place = getattr(status, attribute)\n",
    "        return place.country\n",
    "    return None\n",
    "\n",
    "# get city status\n",
    "def try_city(status, attribute):\n",
    "    if getattr(status, attribute) != None:\n",
    "        place = getattr(status, attribute)\n",
    "        return place.full_name\n",
    "    return None\n",
    "\n",
    "# function that tries to get attribute from object\n",
    "def try_get(status, attribute):\n",
    "    try:\n",
    "        return getattr(status, attribute).encode('utf-8')\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "# open csv file\n",
    "csvFile = open('originalsample.csv', 'a')\n",
    "\n",
    "# create csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "class MyListener(StreamListener):\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        try:\n",
    "            # if this represents a retweet\n",
    "            if try_retweet(status,'retweeted_status'):\n",
    "                status = status.retweeted_status\n",
    "                \n",
    "                # get and sanitize hashtags \n",
    "                hashtags = status.entities['hashtags']\n",
    "                hashtag_list = []\n",
    "                for el in hashtags:\n",
    "                    hashtag_list.append(el['text'])\n",
    "                hashtag_count = len(hashtag_list)\n",
    "\n",
    "                # get and sanitize urls\n",
    "                urls = status.entities['urls']\n",
    "                url_list = []\n",
    "                for el in urls:\n",
    "                    url_list.append(el['url'])\n",
    "                url_count = len(url_list)\n",
    "\n",
    "                # get and sanitize user_mentions\n",
    "                user_mentions = status.entities['user_mentions']\n",
    "                mention_list = []\n",
    "                for el in user_mentions:\n",
    "                    mention_list.append(el['screen_name'])\n",
    "                mention_count = len(mention_list)\n",
    "                \n",
    "                # save it all as a tweet\n",
    "                tweet = [status.id, status.created_at, try_country(status, 'place'), try_city(status, 'place'), status.text.encode('utf-8'), status.lang,\n",
    "                  hashtag_list, url_list, mention_list, \n",
    "                  hashtag_count, url_count, mention_count, \n",
    "                  try_get(status, 'possibly_sensitive'),\n",
    "                  status.favorite_count, status.favorited, status.retweet_count, status.retweeted, \n",
    "                  status.user.statuses_count, \n",
    "                  status.user.favourites_count, \n",
    "                  status.user.followers_count,\n",
    "                  try_get(status.user, 'description'),\n",
    "                  try_get(status.user, 'location'),\n",
    "                  try_get(status.user, 'time_zone')]\n",
    "            \n",
    "                # write to csv\n",
    "                csvWriter.writerow(tweet)\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    "    \n",
    "    # tell us if there's an error\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    "\n",
    "twitter_stream = Stream(auth, MyListener())\n",
    "twitter_stream.sample()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweetdf=pd.read_csv(\"tempdata/originalsample.csv\", names=[\"id\", \"created_at\", \"country\", \"city\", \"text\", \"lang\",\n",
    "                                       \"hashtags\", \"urls\", \"user_mentions\", \n",
    "                                       \"hashtag_count\", \"url_count\", \"mention_count\",\n",
    "                                       \"possibly_sensitive\", \n",
    "                                       \"favorite_count\", \"favorited\", \"retweet_count\", \"retweeted\",\n",
    "                                       \"user_statuses_count\", \"user_favorites_count\",\n",
    "                                       \"user_follower_count\", \"user_description\", \"user_location\", \"user_timezone\"])\n",
    "tweetdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweetdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for English language tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_filtered = tweetdf[tweetdf['lang'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for unique tweet ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_filtered.drop_duplicates(subset='id', take_last=True)\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scraping tweets from the Twitter Streaming API, we use that data to build a feature list that we use to predict how popular an individual tweet will be, measured by a composite score based on the amount of retweets and hearts. We will also use metadata to help us analyze trends in the data, for example if there is a correlation between time of day and retweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updates\n",
    "\n",
    "**11/30 - 12/1 (Yuqi)**\n",
    "\n",
    "Initial exploratory analysis regarding popularity score and hashtags done. It seems like we should rethink our current formula for popularity because the histogram gives extreme strange results and the max score is really high. Need to look into why that might be. \n",
    "\n",
    "All of the correlations that were done between popularity score and other factors came up significant. Could this be due to the large dataset that we are using? Should we be worried about things being labeled as significant not because it actually is significant but because there is so much data that small variations become significant?\n",
    "\n",
    "Also, noticed that some tweets are longer than 140 characters, and I'm not sure why that is either. Further data wrangling probably needed. \n",
    "\n",
    "**12/4 (Yuqi)** Tweets that have emojiis are converted into characters that's throwing off tweet length\n",
    "\n",
    "**12/7 - Yuqi** Took out analysis on how trending topics affects tweets\n",
    "\n",
    "**12/9 - Yuqi & Roseanne** Noticed that z-scoring retweet count and favorite count actually make the standard deviation larger. We also noticed that taking the log of popularity unstandardized gave us the same distribution as taking the log of popularity standardized. It seems like taking the log of our popularity score made a larger impact than standardizing the scores did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the response variable that we are trying to predict using various features of a tweet. The score was originally calculated by adding raw retweet count and favorite counts together, but after some exploratory analysis we chose to z-score retweet and favorite counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Popularity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popularity = [retweets + favs for retweets, favs in zip(df_filtered.retweet_count, df_filtered.favorite_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add popularity column to df\n",
    "df_filtered.loc[:,'popularity']=popularity \n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dftouse = df_filtered.reset_index()\n",
    "dftouse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity Score Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "The distribution of popularity is extremely right-tailed. Later we find that this is explained by the distribution of retweet counts and favorite counts are also extremely right-skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(dftouse['popularity'],bins=100)\n",
    "plt.title(\"Distribution of Popularity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dftouse['popularity'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rethinking how Popularity is Scored\n",
    "The huge standard deviation and extreme ranges suggest that we may need to rethink how we score popularity. We looked more closely at a statistical summary of retweet count and favorite count to decide if any standardization would be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(dftouse['retweet_count'],bins=100)\n",
    "plt.title(\"Distribution of Favorite Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dftouse['retweet_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retweet_stats = dftouse['retweet_count'].describe()\n",
    "retweet_mean = retweet_stats[1]\n",
    "retweet_std = retweet_stats[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(dftouse['favorite_count'],bins=100)\n",
    "plt.title(\"Distribution of Favorite Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dftouse['favorite_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "favorite_stats = dftouse['favorite_count'].describe()\n",
    "favorite_mean = favorite_stats[1]\n",
    "favorite_std = favorite_stats[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these statistics on retweet_count and favorite_count, we realize we want to standardize these two for use later on, otherwise since there are way more retweets than favorites, retweets would get weighted more heavily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftouse = dftouse.rename(columns={'retweet_count': 'retweet_unstandardized', 'favorite_count': 'favorite_unstandardized'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create standardized retweet_count and favorite_count **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use a z-score to standardize retweet counts and favorite counts before adding them together to create the composite popularity score. Using that method, we standardize retweet count and favorites by subtracting the mean and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retweets = [(retweet_count - retweet_mean)/float(retweet_std) for retweet_count in dftouse['retweet_unstandardized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "favorites = [(favorite_count - favorite_mean)/float(favorite_std) for favorite_count in dftouse['favorite_unstandardized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add these as columns to our dftouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftouse.loc[:,'retweet_count']=retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftouse.loc[:,'favorite_count']=favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dftouse.retweet_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dftouse.favorite_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we recalculate popularity, but in the same way as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popularity = [retweets + favs for retweets, favs in zip(dftouse.retweet_count, dftouse.favorite_count)]\n",
    "dftouse.loc[:,'popularity']=popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dftouse['popularity'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Popularity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original histogram of raw popularity scores appeared to have an exponential distribution, so we transformed the data using a log transformation in order to make the relationship between the response variable, popularity, had the explanatory variables (features) more observable. The resulting histogram had reasonable values, so there was no need to further standardize the popularity score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unstandardized_popularity = [retweets + favs for retweets, favs in zip(dftouse.retweet_unstandardized, dftouse.favorite_unstandardized)]\n",
    "dftouse.loc[:,'unstandardized_popularity']=popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftouse['logpopularity']=dftouse['popularity'].apply(np.log)\n",
    "dftouse['logpopularity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(dftouse['logpopularity'])\n",
    "plt.xlabel('Log Popularity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Log Popularity Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtag Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "- http://stackoverflow.com/questions/1894269/convert-string-representation-of-list-to-list-in-python\n",
    "- http://stackoverflow.com/questions/10201977/how-to-reverse-tuples-in-python\n",
    "- http://stackoverflow.com/questions/13925251/python-bar-plot-from-list-of-tuples/34013980#34013980"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What fraction of tweets in the sample use hashtags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_tags_per_tweet = dftouse['hashtag_count']\n",
    "tags_per_tweet = np.array(num_tags_per_tweet)\n",
    "tagfrac = float(len(tags_per_tweet[tags_per_tweet>0]))/float(len(tags_per_tweet))\n",
    "print str(tagfrac)+\" of tweets in the sample use one or more hashtags.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(tags_per_tweet)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Hashtags Used in Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 hashtags "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get a flattened list of all the hashtags used in the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltags=[] \n",
    "for i in dftouse['hashtags']: # grab all the tags and put them into a list\n",
    "    tag = ast.literal_eval(i) # convert string representation of list to list \n",
    "    alltags.append(tag) \n",
    "hashtags = [item for sublist in alltags for item in sublist] # flatten out the nested list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make a bar plot of the 10 most commonly used hashtags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hashfreq = Counter(hashtags) # get the frequency of appearing hashtags\n",
    "commontags = hashfreq.most_common(10) # save the top ten most common hashtags\n",
    "taglabels = zip(*commontags)[0][::-1] # reverse the tuples to go from most frequent to least frequent \n",
    "hashtaglabels = ['#'+i for i in taglabels] # add a pound sign in front of each tag to make it clear that it's a hashtag\n",
    "y_pos = np.arange(len(hashtaglabels)) \n",
    "usefreq = zip(*commontags)[1][::-1] # get the frequency part of the tuple\n",
    "plt.barh(y_pos, usefreq, align='center') # plot horizontal barplot\n",
    "plt.yticks(y_pos, hashtaglabels) \n",
    "plt.title('Top 10 Occuring Hashtags')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top4 = hashfreq.most_common(4)\n",
    "tagdf = pd.DataFrame(dict(alltags=alltags, popularity=dftouse['logpopularity']))\n",
    "\n",
    "for hashtag, _ in top4:\n",
    "    tagdf[hashtag] = [hashtag in hashtags for hashtags in alltags]\n",
    "\n",
    "tagdf['populartags']=tagdf[['MTVStars','ThanksgivingClapBack','ALDUBApproval','ThanksgivingWithBlackFamilies']].sum(axis=1)\n",
    "tagdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in ['MTVStars','ThanksgivingClapBack','ALDUBApproval','ThanksgivingWithBlackFamilies', 'populartags']:\n",
    "    dftouse[column] = tagdf[column]\n",
    "dftouse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweeting about \"Popular\" Topics and Popularity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if you're tweeting about a topic (defined in this case as a hashtag that occurs frequently in our sample), it doesn't affect popularity all that much. Therefore, we chose to leave hashtags out of our model because it didn't seem as though hashtags affected our model that much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(tagdf['populartags'], tagdf['popularity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Hashtags vs. Popularity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pearsonr(dftouse['hashtag_count'],dftouse['logpopularity'])\n",
    "plt.scatter(dftouse['hashtag_count'],dftouse['logpopularity'])\n",
    "plt.ylabel('Log Popularity Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between length of tweet and popularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweet_len = [len(text) for text in dftouse['text']]\n",
    "print pearsonr(tweet_len,dftouse['logpopularity'])\n",
    "plt.scatter(tweet_len,dftouse['logpopularity'])\n",
    "plt.ylabel('Log Popularity Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that some tweets are longer than 140 characters because tweets using emojiis are converted into unicode characters, which is being counted into tweet length. The below text shows a tweet that uses emojiis. The distribution of tweet length appears fairly uniform so we decided not to remove emojii text from the analysis. In addition, fewer than 5.6% of our tweets went over the 140 character mark, so we decided that the effect was negligible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character Length and Emojiis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_len_array = np.array(tweet_len)\n",
    "idx = np.where(tweet_len_array > 140)[0].tolist()\n",
    "df_filtered_by_length = dftouse['text'].filter(idx).copy()\n",
    "df_over140 = df_filtered_by_length.reset_index()\n",
    "df_over140['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of tweets that use emojiis\n",
    "float(len(idx))/float(len(dftouse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between presence of links and popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe only has information about links and it would have been too complex to differntiate between images links and other links, so differentiating between images and other urls for this. It appears that having more than one link is correlated with decreased popularity scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pearsonr(dftouse['url_count'],dftouse['logpopularity'])\n",
    "plt.scatter(dftouse['url_count'],dftouse['logpopularity'])\n",
    "plt.ylabel('Log Popularity Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between user mentions and popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears as though increasing the number of user mentions is correlated with a decrease in popularity score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pearsonr(dftouse['mention_count'],dftouse['logpopularity'])\n",
    "plt.scatter(dftouse['mention_count'],dftouse['logpopularity'])\n",
    "plt.ylabel('Log Popularity Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation for number of retweets and hearts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There generally appears to be a positive correlation between retweet count and hearts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print pearsonr(dftouse['retweet_count'],dftouse['favorite_count'])\n",
    "plt.scatter(dftouse['retweet_count'],dftouse['favorite_count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location\n",
    "\n",
    "**Update 12/4 (Yuqi)** Originally we had planned to do exploratory analysis on popular topics that people tweet about by city or state, but after taking a look at our data, we found that 3.2% of tweets were geo-tagged, so we ultimately chose to forego this analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fraction of Tweets that are Geo-tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totaltweets = float(len(dftouse['country'])) # total number of tweets in sample\n",
    "countryfrac = float(sum(map(lambda r: int(isinstance(r, str)), dftouse['country'])))/totaltweets\n",
    "cityfrac = float(sum(map(lambda r: int(isinstance(r, str)), dftouse['city'])))/totaltweets\n",
    "print str(cityfrac)+\" of tweets in the sample are geo-tagged with a city.\"\n",
    "print str(countryfrac)+\" of tweets in the sample are geo-tagged with a country.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date_objects = [datetime.strptime(each, '%Y-%m-%d %H:%M:%S') for each in dftouse['created_at']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When are tweets posted throughout the week?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we used the Twitter Streaming API, most of the tweets are posted on a Tuesday, since that's when we scraped the tweets. This is also the case for the spike in tweets posted between midnight and 4am (localized time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "day_objects = [each.weekday() for each in date_objects]\n",
    "x_pos = Counter(day_objects).keys()\n",
    "height = Counter(day_objects).values()\n",
    "days = ('Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday')\n",
    "plt.bar(x_pos,height,align='center')\n",
    "plt.xticks(x_pos, days) \n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Tweets Throughout the Week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When are tweets posted during the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hour_objects = [each.hour for each in date_objects]\n",
    "plt.hist(hour_objects)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram is helpful, but a polar histogram could possibly visualize our data in a more intuitive way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    data = hour_objects\n",
    "    axes = plot_clock(data)\n",
    "    for ax in axes:\n",
    "        realign_polar_xticks(ax)\n",
    "    plt.show()\n",
    "\n",
    "def realign_polar_xticks(ax):\n",
    "    pass\n",
    "    for theta, label in zip(ax.get_xticks(), ax.get_xticklabels()):\n",
    "        theta = theta * ax.get_theta_direction() + ax.get_theta_offset()\n",
    "        theta = np.pi/2 - theta\n",
    "        y, x = np.cos(theta), np.sin(theta)\n",
    "        if x >= 0.1:\n",
    "            label.set_horizontalalignment('left')\n",
    "        if x <= -0.1:\n",
    "            label.set_horizontalalignment('right')\n",
    "        if y >= 0.5:\n",
    "            label.set_verticalalignment('bottom')\n",
    "        if y <= -0.5:\n",
    "            label.set_verticalalignment('top')\n",
    "\n",
    "def plot_clock(data):\n",
    "    def hour_formatAM(x, p):\n",
    "        hour = x * 6 / np.pi\n",
    "        return '{:0.0f}:00'.format(hour) if x > 0 else '12:00'\n",
    "\n",
    "    def hour_formatPM(x, p):\n",
    "        hour = x * 6 / np.pi\n",
    "        return '{:0.0f}:00'.format(hour + 12) if x > 0 else '24:00'\n",
    "\n",
    "    def plot(ax, theta, counts, formatter):\n",
    "        colors = plt.cm.jet(theta / 12.0)\n",
    "        ax.bar(theta, counts, width=np.pi/6, color=colors, alpha=0.5)\n",
    "        ax.xaxis.set_major_formatter(tkr.FuncFormatter(formatter))\n",
    "\n",
    "    plt.rcParams['font.size'] = 8\n",
    "\n",
    "    bins = np.r_[0, 0.5:12, 12, 12.5:24,  23.99999]\n",
    "    counts = np.histogram(data,bins)[0]\n",
    "\n",
    "    counts[13] += counts[0]\n",
    "    counts[-1] += counts[13]\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(22, 12), dpi=200,\n",
    "                             subplot_kw=dict(projection='polar'))\n",
    "    fig.subplots_adjust(wspace=0.5)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set(theta_offset=np.pi/2, theta_direction=-1,\n",
    "               xticks=np.arange(0, np.pi*2, np.pi/6),\n",
    "               yticks=np.arange(1, counts.max()))\n",
    "\n",
    "    plot(axes[0], bins[1:13] * np.pi / 6, counts[1:13], hour_formatAM)\n",
    "    plot(axes[1], bins[14:26] * np.pi / 6, counts[14:26], hour_formatPM)\n",
    "    return axes\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between time of day and tweet popularity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not appear to be a clear relationship between the time of day that a tweet is created and its popularity score. There does appear to be some cyclical change, but it's hard to tell based on the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(hour_objects, dftouse['logpopularity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Since there does appear to be a slight relationship, we will include this in the prediction model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert hour ints to strings to make the model evaluate hours as categorical variables \n",
    "string_hours = [str(hour) for hour in hour_objects]\n",
    "dftouse['hour_posted']=string_hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between day of the week posted and popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears uniform, more so than hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(day_objects, dftouse['logpopularity'])\n",
    "x_pos_x=range(0,7)\n",
    "plt.xticks(x_pos_x, days)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The distribution of retweets and favorites over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were unable to plot this graph using the standardized retweet count so we chose to display the relationship using unstandardized values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot_date(date_objects, dftouse['favorite_unstandardized'], alpha=.1, color='r')\n",
    "plt.plot_date(date_objects, dftouse['retweet_unstandardized'], alpha=.1, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User's followers correlated with popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_follower_count = dftouse['user_follower_count'] \n",
    "print pearsonr(user_follower_count,dftouse['logpopularity'])\n",
    "plt.scatter(user_follower_count,dftouse['logpopularity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining positive/negative words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sentiment lookup dictionaries, score tweets based on how positive/negative they are.\n",
    "\n",
    "**11/29 - Roseanne**\n",
    "Used a basic list of positive/negative words to begin with, no weights or other information beyond positive/negative. Appears to miss a bunch of tokens (1812/892606 found).\n",
    "\n",
    "**12/1 - Roseanne**\n",
    "Tried LabMT, using code provided. Rate is a lot better (7016/892606).\n",
    "\n",
    "**12/4 - Roseanne**\n",
    "Realized number of tokens (892606) was total tokens instead of unique tokens (83093). Still a lot but more tokens found than expected. LabMT is probably the better choice, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we tested the completeness of the lookup dictionaries that we originally chose to score text sentiment. The first positive.txt and negative.txt dictionaries are from UNC. Due to the nature of Twitter, many words and phrases tweeted will not be standard English and it is unlikely that we will find ratings for all of them in our dictionaries. We chose to go with LabMT as our dictionary since it was built for Twitter and therefore contained more words that we looked up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#notes: Unicode in texts (probably emoticons? should we find a way to categorize those?)\n",
    "\n",
    "#load dicts into lookup, map words to pos or neg value\n",
    "#current dict: not sure where it's from?\n",
    "#1812 of 83093 words in lookup.\n",
    "lookup = {}\n",
    "with open('positive.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        word = line[:-1]\n",
    "        lookup[word] = 1\n",
    "with open('negative.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        word = line[:-1]\n",
    "        lookup[word] = -1\n",
    "\n",
    "# uses LabMT for scoring, see http://neuro.imm.dtu.dk/wiki/LabMT\n",
    "# 7016 of 83093 words in LabMT.\n",
    "url = 'http://www.plosone.org/article/fetchSingleRepresentation.action?uri=info:doi/10.1371/journal.pone.0026752.s001'\n",
    "labmt = pd.read_csv(url, skiprows=2, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used NLTK to handle much of the text parsing. We also used the NLTK tokenizer which breaks up punctuation and contractions, so words like \"can't\" are broken up into \"ca\" \"n't\", as well as emoticons such as \":)\" which become \":\", \")\". This causes some data to be lost, but ultimately these are neutral or stop words that do not have a significant impact on sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# you'll need to download NLTK resource: nltk.download()\n",
    "# or use terminal: sudo python -m nltk.downloader -d /usr/local/share/nltk_data all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we compiled all the tweets into a format that NLTK could work with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#text = reduce(lambda x,y: x+y, dftouse['text'].apply(lambda x: [x])) # list of strings, functionally identical to dftouse['text']\n",
    "tweetstext = reduce(lambda x,y: x + '\\n' + y, dftouse['text']) # string of concatenated texts, all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# notice: tokenizer puts punctuation as their own tokens, ex. separates hashtags, etc.\n",
    "tokens = nltk.word_tokenize(tweetstext.decode('utf-8','ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we looked at how often individual tokens appear and checked to see how many appeared in each of the dictionaries (we are using two dictionaries, the UNC and LabMT one). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Number of tokens:\", len(tokens)\n",
    "fdist = nltk.FreqDist(tokens)\n",
    "utokens = fdist.keys()\n",
    "print \"Unique tokens:\", len(utokens)\n",
    "print \"Tokens that appear only once:\", len(fdist.hapaxes())\n",
    "#fdist.most_common(50)\n",
    "inlookup = []\n",
    "notfoundlookup = []\n",
    "inlabmt = []\n",
    "notfoundlabmt = []\n",
    "for key in utokens:\n",
    "    if key in lookup.keys():\n",
    "        inlookup.append(key)\n",
    "    else:\n",
    "        notfoundlookup.append(key)\n",
    "    if key in labmt.index:\n",
    "        inlabmt.append(key)\n",
    "    else:\n",
    "        notfoundlabmt.append(key)\n",
    "print \"{} of {} words in lookup.\".format(len(inlookup), len(utokens))\n",
    "print inlookup[:10]\n",
    "\n",
    "print \"{} of {} words in LabMT.\".format(len(inlabmt), len(utokens))\n",
    "print inlabmt[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that LabMT found more words so we chose to go with LabMT in our final analysis. Plus, LabMT computes sentiment on a scale whereas the UNC dictionaries were binary. LabMT gave out more information which we thought would be more useful for our model. We also took into consideration that some tokens would not have sentiment ratings, such as the URL tokens or hapaxes, which are tokens that appear only once in our tweets sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of words don't appear in our dictionary, but we think that's okay because many of these are the result of formatting in Tweets that causes the tokenizer difficulty in parsing, or are unique words that are unlikely to throw off our scoring, such as URLs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fdist.hapaxes()[:10] #lots of links, Unicode included here, is it worth filtering out these/punctuation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utokens_ = [x for x in utokens if x[:6] != '//t.co']\n",
    "urltokens = [x for x in utokens if x[:6] == '//t.co']\n",
    "print \"Non-URL tokens:\", len(utokens_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12/4 - Roseanne**\n",
    "\n",
    "Scoring - build columns for scoring text, one on the raw text, one on text that ignores words not in our dictionary, and one that shows us which words are not in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average of entire tweet over unigrams\n",
    "average = labmt.happiness_average.mean()\n",
    "happiness = (labmt.happiness_average - average).to_dict()\n",
    "\n",
    "# this is amazingly inefficient sorry\n",
    "def score(text):\n",
    "    words = nltk.word_tokenize(text.decode('utf-8','ignore'))\n",
    "    return sum([happiness.get(word.lower(), 0.0) for word in words]) / len(words)\n",
    "\n",
    "def scoreNoNeutrals(text):\n",
    "    words = nltk.word_tokenize(text.decode('utf-8','ignore'))\n",
    "    notscored = [word for word in words if happiness.get(word.lower(), 0.0) == 0.0]\n",
    "    return sum([happiness.get(word.lower(), 0.0) for word in words]) / max((len(words) - len(notscored)),1)\n",
    "\n",
    "def scored(text):\n",
    "    words = nltk.word_tokenize(text.decode('utf-8','ignore'))\n",
    "    return [word for word in words if happiness.get(word.lower(), 0.0) != 0.0]\n",
    "\n",
    "def notScored(text):\n",
    "    words = nltk.word_tokenize(text.decode('utf-8','ignore'))\n",
    "    return [word for word in words if happiness.get(word.lower(), 0.0) == 0.0]\n",
    "\n",
    "\n",
    "dftouse['text'].apply(score).mean()\n",
    "dftouse['sentiment'] = dftouse['text'].apply(score)\n",
    "dftouse['sentimentnoneutrals'] = dftouse['text'].apply(scoreNoNeutrals)\n",
    "dftouse['scored'] = dftouse['text'].apply(scored)\n",
    "dftouse['notscored'] = dftouse['text'].apply(notScored)\n",
    "dftouse[['text','sentiment', 'sentimentnoneutrals', 'scored', 'notscored']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12/4 - Roseanne**\n",
    "\n",
    "Checking how our lookup and scoring is working.\n",
    "\n",
    "Sentiment score ranges from approx. -3 to 3, with a mean close to 0.1, or roughly neutral.\n",
    "\n",
    "Hapaxes (words that appear only once in the Tweets we're analyzing) are a surprisingly large percentage of our tokens (~55000 out of 83000). A lot of them are URLs (19812), which we can probably ignore, or include a Unicode character or formatting that caused the tokenizer to behave oddly. Would it be worth it to try to filter out punctuation, or manually add them to our lookup (ex. replace .!?s with spaces, or add tokens such as '...'. If we add them, how do we generate a score for them?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dftouse.sentiment.min(), dftouse.sentiment.max(), dftouse.sentiment.mean()\n",
    "print dftouse.sentimentnoneutrals.min(), dftouse.sentimentnoneutrals.max(), dftouse.sentimentnoneutrals.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftouse.loc[dftouse.sentimentnoneutrals==dftouse.sentimentnoneutrals.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftouse.loc[dftouse.sentimentnoneutrals==dftouse.sentimentnoneutrals.min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 Most Common Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the fifty most common tokens in our tweets to get an idea of what appears most often. Many of these are punctuation, which generally do not have a consistent effect on sentiment, or are neutral words that do not factor into our sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for word, freq in fdist.most_common(50):\n",
    "    print word, score(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Ngram Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our approach to sentiment analysis is very simplistic, in large part because we look at words individually. However, in sentences words are not independent of each other and their meanings can combine in different ways to affect the sentiment. For example, the phrase \"not bad\" would be considered positive, but our sentiment would score it as negative because \"not\" and \"bad\" are generally negative. To examine the extent of which this would affect our sentiment scoring, we looked at bigrams and trigrams to understand how often and which bigrams/trigrams could be scored differently than the unigrams. We found that it wasn't a significant enough difference to include them in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by finding the bigrams where the constituent elements are strongly associated with each other, i.e. they often occur together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scoring the association\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print scored[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Most Strongly Associated Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strongly associated bigrams occur when the elements appear together consistently. For example, if we see a \"https\" token, the chance that the next token is \":\" is high, giving the bigram (\"https\", \":\") a high association score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finds most associated bigrams\n",
    "top_bigrams = finder.nbest(bigram_measures.raw_freq, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we remove stopwords and punctuation from our list of tokens in order to see more meaningful tokens in our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create bigrams for each tweet\n",
    "bigrams = dftouse['text'].apply(lambda x: list(nltk.bigrams(nltk.word_tokenize(x.decode('utf-8','ignore')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.feature_extraction import text \n",
    "stopwords=text.ENGLISH_STOP_WORDS\n",
    "punctuation = string.punctuation[:6] + string.punctuation[7:]\n",
    "filtered = list(punctuation) + ['https','http','//t.co'] + list(stopwords)\n",
    "# built a list of tokens that aren't punctuation or stopwords\n",
    "tokens_ = [x for x in tokens if x not in filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of bigram frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find 50 most common bigrams\n",
    "bigramfreq = nltk.FreqDist(nltk.bigrams(tokens_))\n",
    "bigramfreq.most_common(20)\n",
    "frequencies = [freq for bigram, freq in bigramfreq.items()]\n",
    "# plot distribution\n",
    "plt.hist(frequencies, bins=100)\n",
    "plt.title(\"Distribution of Bigram Frequencies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams vs Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Count important bigrams **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are considered to be bigrams that show up 50 or more times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigrams_sorted = sorted(bigramfreq.items(), key=lambda x: -x[1])\n",
    "print bigrams_sorted[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bigram is important if it's associated more than 50 times\n",
    "important_bigrams = [(bigram, val) for bigram, val in bigrams_sorted if val >= 50]\n",
    "len(important_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** What percentage of our bigrams are important? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frac = len(important_bigrams) / float(len(bigrams))\n",
    "print frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us hope that the presence of bigrams won't throw off our calculations too badly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Does manual scoring differ from our unigram scores? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign scores to what we think is appropriate\n",
    "manual_scores = bigrams_sorted[:20]\n",
    "bigrams_tuple = [str(bigram) for bigram, frequency in manual_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually score the bigrams to see which are positive and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigramdf = pd.DataFrame.from_items([('bigrams', bigrams_tuple)])\n",
    "manual_ratings = [\"Pos\", \"Pos\", \"Pos\", \"Neg\", \"Neg\", \"Pos\", \"Neg\", \"Neg\", \"Pos\", \"Pos\", \"Pos\", \n",
    "                  \"Neg\", \"Neg\", \"Neg\", \"Neg\", \"Pos\", \"Pos\", \"Pos\", \"Pos\", \"Neg\"]\n",
    "bigramdf['manual_ratings']= manual_ratings\n",
    "bigramdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do some unigram scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scoring function for lists of tokens\n",
    "def scoreTokens(words):\n",
    "    return sum([happiness.get(word.lower(), 0.0) for word in words]) / len(words)\n",
    "\n",
    "def scoreNoNeutralsTokens(words):\n",
    "    notscored = [word for word in words if happiness.get(word.lower(), 0.0) == 0.0]\n",
    "    return sum([happiness.get(word.lower(), 0.0) for word in words]) / max((len(words) - len(notscored)),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams_text = [[word1, word2] for (word1, word2), frequency in manual_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our unigram scores including neutrals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass bigrams to score function\n",
    "unigram_scores_neutrals = [sum([happiness.get(word.lower(), 0.0) for word in bigram]) / len(bigram) for bigram in bigrams_text]\n",
    "# # print whether they're positive or neutral\n",
    "unigram_bool_neutrals = [\"Pos\" if score > 0 else \"Neg\" for score in unigram_scores_neutrals]\n",
    "bigramdf['unigram_ratings_neutrals']= unigram_bool_neutrals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our unigram scores without neutrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass bigrams to no neutrals score function\n",
    "unigram_scores_no_neutrals = [scoreNoNeutralsTokens(bigram) for bigram in bigrams_text]\n",
    "# print whether they're positive or neutral\n",
    "unigram_bool_no_neutrals = [\"Pos\" if score > 0 else \"Neg\" for score in unigram_scores_neutrals]\n",
    "bigramdf['unigram_ratings_no_neutrals']= unigram_bool_no_neutrals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our bigramdf now includes manual_ratings, unigram_ratings with neutrals and unigram_ratings without neutrals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigramdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the accuracy of our unigram scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate percent difference neutrals\n",
    "bigramdf['neutral_manual_same'] = [ 1 if manual == neutral else 0 for manual, neutral in zip(\n",
    "                                    bigramdf['manual_ratings'],\n",
    "                                    bigramdf['unigram_ratings_neutrals'])]\n",
    "neutralcount = bigramdf['neutral_manual_same'].sum()\n",
    "# calculate percent difference no neutrals\n",
    "neutralcount/float(len(bigramdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that our unigram scoring seems pretty accurate since 90% of our manual scoring of bigrams actually match our unigram scores. Now we see if this holds for our no neutrals scoring as wel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# noneutral_manual_same\n",
    "bigramdf['noneutral_manual_same'] = [ 1 if manual == neutral else 0 for manual, neutral in zip(\n",
    "                                    bigramdf['manual_ratings'],\n",
    "                                    bigramdf['unigram_ratings_no_neutrals'])]\n",
    "noneutralcount = bigramdf['noneutral_manual_same'].sum()\n",
    "noneutralcount/float(len(bigramdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigramdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same thing with trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder = TrigramCollocationFinder.from_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finds most associated trigrams\n",
    "top_trigrams = finder.nbest(trigram_measures.raw_freq, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define trigrams\n",
    "trigrams = dftouse['text'].apply(lambda x: list(nltk.trigrams(nltk.word_tokenize(x.decode('utf-8','ignore')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finds the most common 20\n",
    "tokens_ = [x for x in tokens if x not in filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot distribution of trigram frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find 50 most common bigrams\n",
    "trigramfreq = nltk.FreqDist(nltk.trigrams(tokens_))\n",
    "trigramfreq.most_common(20)\n",
    "frequencies = [freq for trigram, freq in trigramfreq.items()]\n",
    "# plot distribution\n",
    "plt.hist(frequencies, bins=100)\n",
    "plt.title(\"Distribution of Trigram Frequencies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigrams vs Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Count important trigrams **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trigrams_sorted = sorted(trigramfreq.items(), key=lambda x: -x[1])\n",
    "print trigrams_sorted[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trigram is important if it's associated more than 50 times\n",
    "important_trigrams = [(trigram, val) for trigram, val in trigrams_sorted if val >= 50]\n",
    "len(important_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As before, the percentage of our trigrams that are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frac = len(important_trigrams) / float(len(trigrams))\n",
    "print frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare manual and unigram scores of trigrams.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign scores to what we think is appropriate\n",
    "manual_scores = trigrams_sorted[:20]\n",
    "trigrams_tuple = [str(trigram) for trigram, frequency in manual_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigramdf = pd.DataFrame.from_items([('trigrams', trigrams_tuple)])\n",
    "manual_ratings = [\"Pos\", \"Pos\", \"Pos\", \"Neg\", \"Neg\", \"Pos\", \"Neg\", \"Neg\", \"Pos\", \"Pos\", \"Pos\", \n",
    "                  \"Neg\", \"Neg\", \"Neg\", \"Neg\", \"Pos\", \"Pos\", \"Pos\", \"Pos\", \"Neg\"]\n",
    "trigramdf['manual_ratings']= manual_ratings\n",
    "trigramdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram scoring"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# scoring function for lists\n",
    "def score(words):\n",
    "    return sum([happiness.get(word.lower(), 0.0) for word in words]) / len(words)\n",
    "\n",
    "def scoreNoNeutrals(words):\n",
    "    notscored = [word for word in words if happiness.get(word.lower(), 0.0) == 0.0]\n",
    "    return sum([happiness.get(word.lower(), 0.0) for word in words]) / max((len(words) - len(notscored)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigrams_text = [[word1, word2, word3] for (word1, word2, word3), frequency in manual_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring with neutrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass bigrams to score function\n",
    "unigram_scores_neutrals = [sum([happiness.get(word.lower(), 0.0) for word in trigram]) / len(bigram) for trigram in trigrams_text]\n",
    "# # print whether they're positive or neutral\n",
    "unigram_bool_neutrals = [\"Pos\" if score > 0 else \"Neg\" for score in unigram_scores_neutrals]\n",
    "trigramdf['unigram_ratings_neutrals']= unigram_bool_neutrals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring without neutrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass bigrams to no neutrals score function\n",
    "unigram_scores_no_neutrals = [scoreNoNeutralsTokens(bigram) for bigram in bigrams_text]\n",
    "# print whether they're positive or neutral\n",
    "unigram_bool_no_neutrals = [\"Pos\" if score > 0 else \"Neg\" for score in unigram_scores_neutrals]\n",
    "bigramdf['unigram_ratings_no_neutrals']= unigram_bool_no_neutrals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of scoring with and without neutrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate percent difference neutrals\n",
    "trigramdf['neutral_manual_same'] = [ 1 if manual == neutral else 0 for manual, neutral in zip(\n",
    "                                    trigramdf['manual_ratings'],\n",
    "                                    trigramdf['unigram_ratings_neutrals'])]\n",
    "neutralcount = trigramdf['neutral_manual_same'].sum()\n",
    "# noneutral_manual_same\n",
    "bigramdf['noneutral_manual_same'] = [ 1 if manual == neutral else 0 for manual, neutral in zip(\n",
    "                                    bigramdf['manual_ratings'],\n",
    "                                    bigramdf['unigram_ratings_no_neutrals'])]\n",
    "noneutralcount = bigramdf['noneutral_manual_same'].sum()\n",
    "# calculate percent difference neutrals, and no neutrals\n",
    "neutralcount/float(len(trigramdf)), noneutralcount/float(len(bigramdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram, Bigram, Trigram comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoredunigrams = [(x, y, scoreNoNeutralsTokens([x])) for x,y in fdist.items() if y >= 20]\n",
    "\n",
    "posunigrams = [(x,y,z) for x,y,z in scoredunigrams if z >= 1]\n",
    "negunigrams = [(x,y,z) for x,y,z in scoredunigrams if z <= 1]\n",
    "neuunigrams = [(x,y,z) for x,y,z in scoredunigrams if z < 1 and z > -1]\n",
    "\n",
    "print \"unigrams positive:\", len(posunigrams), \"negative:\", len(negunigrams), \"neutral:\", len(neuunigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoredbigrams = [(x, y, scoreNoNeutralsTokens(x)) for x,y in bigramfreq.items() if y >= 20]\n",
    "\n",
    "posbigrams = [(x,y, z) for x,y,z in scoredbigrams if z >= 1]\n",
    "negbigrams = [(x,y, z) for x,y,z in scoredbigrams if z <= 1]\n",
    "neubigrams = [(x,y, z) for x,y,z in scoredbigrams if z < 1 and z > -1]\n",
    "\n",
    "print \"bigrams positive:\", len(posbigrams), \"negative:\", len(negbigrams), \"neutral:\", len(neubigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoredtrigrams = [(x, y, scoreNoNeutralsTokens(x)) for x,y in trigramfreq.items() if y >= 20]\n",
    "\n",
    "postrigrams = [(x,y,z) for x,y,z in scoredtrigrams if z >= 1]\n",
    "negtrigrams = [(x,y,z) for x,y,z in scoredtrigrams if z <= 1]\n",
    "neutrigrams = [(x,y,z) for x,y,z in scoredtrigrams if z < 1 and z > -1]\n",
    "\n",
    "print \"trigrams positive:\", len(postrigrams), \"negative:\", len(negtrigrams), \"neutral:\", len(neutrigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(30, 30), \n",
    "                         tight_layout=True)\n",
    "\n",
    "grams = [(1, scoredunigrams, 'unigrams'),\n",
    "        (2, scoredbigrams, 'bigrams'),\n",
    "        (3, scoredtrigrams, 'trigrams')]\n",
    "\n",
    "for i, dist, name in grams:\n",
    "    plt.subplot(3,1,i)\n",
    "    flattened = reduce(lambda x,y: x+y, [[z]*y for x,y,z in dist])\n",
    "    #plt.hist(plotpostri+plotnegtri+plotneutri, color=['b','r', 'g'], label=['positive', 'negative', 'neutral'])\n",
    "    plt.hist(flattened)\n",
    "    plt.title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i, dist, name in grams:\n",
    "    flattened = reduce(lambda x,y: x+y, [[z]*y for x,y,z in dist])\n",
    "    plt.hist(flattened, alpha=0.2, label=name)\n",
    "plt.legend(frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color = ['b','r','g']\n",
    "plt.figure()\n",
    "for i, dist, name in grams:\n",
    "    yscores = [z for x,y,z in dist]\n",
    "    xvals = [i + (np.random.rand() - 0.5)/2. for y in yscores]\n",
    "    plt.scatter(xvals, yscores, alpha=0.2, label=name, c=color[i-1])\n",
    "plt.gca().axes.get_xaxis().set_ticks([])\n",
    "plt.xticks([1.,2.,3.],['unigrams','bigrams','trigrams'])\n",
    "plt.title('Distribution of sentiment scores over ngrams')\n",
    "plt.ylabel('Sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12/6 - Roseanne**\n",
    "\n",
    "Working on prediction. Note: HW5 prediction is used to predict if sentiment is positive or negative, but we want to use this to predict how popular something is, not sure how to do that. Xarray below was built on text, but we should probably be doing something like HW2 and using sentiment or sentimentnoneutrals as one of the factors instead. I have been doing too much text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dftouse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import glm, ols\n",
    "formula = 'logpopularity ~ hashtags + url_count + mention_count + user_follower_count + sentimentnoneutrals'\n",
    "model = ols(formula, dftouse.head(2000)).fit()\n",
    "print \"R^2:\", model.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import glm, ols\n",
    "formula = 'logpopularity ~ hashtags + url_count + mention_count + user_follower_count + sentimentnoneutrals + created_at'\n",
    "model = ols(formula, dftouse.head(2000)).fit()\n",
    "print \"R^2:\", model.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We model popularity as a function of features of the tweet and the user that posted it. Hashtags, links, mentioned users, sentiment, and time of posting are all features that can affect how many people see the tweet and the likelihood of a user retweeting and thus expanding the number of users who see the tweet. We also use the poster's follower count as a feature to account for users whose higher follower counts means that their initial audience is larger to begin with and can skew their popularity score compared to users with lower follower counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "formula = 'logpopularity ~ MTVStars + ThanksgivingClapBack + ALDUBApproval + ThanksgivingWithBlackFamilies + url_count + mention_count + user_follower_count + sentimentnoneutrals + hour_posted'\n",
    "model = ols(formula, dftouse.head(2000)).fit()\n",
    "print \"R^2:\", model.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary test on a basic OLS regression model we have fairly low R^2. It's possible to run the following code to see if there's just something wrong in our formula (i.e. can we get a higher R^2 with a different combination of features), but it's likely that all our results are going to have a low R^2 by the nature of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "# final, final version \n",
    "import itertools\n",
    "formulabase = 'popularity ~ '\n",
    "variables = ['hashtags', 'url_count', 'mention_count', 'user_follower_count', 'sentimentnoneutrals', 'date_objects', 'created_at']\n",
    "' + '.join(variables)\n",
    "\n",
    "testresults = {}\n",
    "\n",
    "for i in range(1,len(variables)):\n",
    "    #print ' + '.join(list(itertools.combinations(variables, i)))\n",
    "    for var in list(itertools.combinations(variables, i)):\n",
    "        testformula = formulabase + ' + '.join(var)\n",
    "        print testformula, \"running......\"\n",
    "        testmodel = ols(testformula, dftouse).fit()\n",
    "        testresults[testformula] = testmodel.rsquared\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this takes forever to run + overheated my laptop\n",
    "# sns.lmplot(x=\"sentimentnoneutrals\", y=\"logpopularity\", hue=\"user_follower_count\", data=dftouse.head(), size = 7, aspect=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(dftouse['logpopularity'], model.predict())\n",
    "plt.plot([-2,16],[-2,16], 'k', label=\"slope 1\", linewidth=2)\n",
    "plt.xlim(-1.5,16)\n",
    "plt.ylim(-1.5,16)\n",
    "plt.xlabel('Actual Log Popularity Score')\n",
    "plt.ylabel('Predicted Log Popularity Score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
