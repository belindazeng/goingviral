{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Popularity: Using Text and Content Analysis to Examine Shared Characteristics of Popular Posts on Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A CS109 Final Project by Belinda Zeng, Roseanne Feng, Yuqi Hou, and Zahra Mahmood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](https://studentshare.net/content/wp-content/uploads/2015/05/53a0e7d640b31_-_unknown-3-51047042.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter (https://twitter.com) is social network, real-time news media service, and micro-blogging service where users can use text, photos, and videos to express moments or ideas in 140-characters or less. These 140-character messages are called \"tweets.” According to Twitter’s website, millions of tweets are shared in real time, every day. Registered users can read and post tweets, favorite other people’s tweets, retweet other people’s posts, favorite tweets, and follow other accounts. Unregistered users can read tweets from public accounts. \n",
    "\n",
    "In today's day and age of Twitter, popularity is measured in hearts, retweets, follows, and follow-backs. What posts get popular over time? What seems to resonate most with people? Do positive or negative sentiments invite more engagement? In this project, we use Twitter's publically available archive of content to  like to examine some of the shared characteristics of popular posts, including length of post, visual content, positivity, negativity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our idea came from a desire to understand how movements such as #BlackLivesMatter and #Ferguson begin on Twitter as well as a general desire to know what makes a post popular. We chose to focus on Tweets on an individual level and to use natural language processing to be able to understand and predict what makes posts popular.\n",
    "\n",
    "One paper that is related to our work is a paper from Cornell titled, [The effect of wording on message propagation: Topic- and author-controlled natural experiments on Twitter](https://chenhaot.com/pages/wording-for-propagation.html), which compaired pairs of tweets containing the same url and written by the same user but employing different wording to see which version attracted more retweets. Twitter itself has published research on [What fuels a Tweet’s engagement?](https://blog.twitter.com/2014/what-fuels-a-tweets-engagement) Their research found that adding video, links and photos all result in an increase in the number of retweets and even breaking down those results by industry. Inspired by previous research, we sought to include sentiment analysis in our understanding of what made a Tweet popular. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How does the distribution of retweets and hearts vary for a post depending on the time of day when tweet is created?\n",
    "2. How does positive and negative sentiment affect popularity? \n",
    "3. What Tweets do we think will become popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is publicly available via the Twitter Static API that gets queries based on specific parameters. We limited the data set to look at tweets within a specified period of time. We are storing the data in CSV files for now. To reduce file-sizes, we will try to have multiple CSVs so that we don't load too much data into memory. If data exceeds computer memory, we will consider AWS/SQL database alternatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up oauth and a app on Twitter (to getthe consumer key & secret and access token and secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# great resource where I got all this \n",
    "# http://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/\n",
    "\n",
    "import tweepy\n",
    "import json\n",
    "from tweepy import OAuthHandler\n",
    " \n",
    "consumer_key = 'lun6TR6KpaISisFdGnQ5Eo8v5'\n",
    "consumer_secret = 'hmwEtnfvTfI6CljEKKtIGjahG4NcFQvLBXhOnPyFHmAqNZ9fVV'\n",
    "access_token = '3004335028-UKSgKFDbaBLNWTzXQFrBRDwVOKo0JR475KYY3LW'\n",
    "access_secret = 'pA6MeW4NYsv3tL0MRvjI1oBqdUZc0os11gesdNVkeLpX2'\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial approach is to create a random sample that consists of 1% of tweets. This involves using tweepy and the sample call from the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# final, final version \n",
    "\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "# get retweet status\n",
    "def try_retweet(status, attribute):\n",
    "    try:\n",
    "        if getattr(status, attribute):\n",
    "            return True\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "# function that tries to get attribute from object\n",
    "def try_get(status, attribute):\n",
    "    try:\n",
    "        return getattr(status, attribute).encode('utf-8')\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "# open csv file\n",
    "csvFile = open('smallsample.csv', 'a')\n",
    "\n",
    "# create csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "class MyListener(StreamListener):\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        try:\n",
    "            # save relevant components of the tweet\n",
    "            \n",
    "            # get and sanitize hashtags \n",
    "            hashtags = status.entities['hashtags']\n",
    "            hashtag_list = []\n",
    "            for el in hashtags:\n",
    "                hashtag_list.append(el['text'])\n",
    "            hashtag_count = len(hashtag_list)\n",
    "            \n",
    "            # get and sanitize urls\n",
    "            urls = status.entities['urls']\n",
    "            url_list = []\n",
    "            for el in urls:\n",
    "                url_list.append(el['url'])\n",
    "            url_count = len(url_list)\n",
    "            \n",
    "            # get and sanitize user_mentions\n",
    "            user_mentions = status.entities['user_mentions']\n",
    "            mention_list = []\n",
    "            for el in user_mentions:\n",
    "                mention_list.append(el['screen_name'])\n",
    "            mention_count = len(mention_list)\n",
    "            # save it all as a tweet\n",
    "            tweet = [status.created_at, status.text.encode('utf-8'), status.place, status.lang, status.coordinates, \n",
    "              hashtag_list, url_list, mention_list, \n",
    "              hashtag_count, url_count, mention_count, \n",
    "              try_get(status, 'possibly_sensitive'),\n",
    "              status.favorite_count, status.favorited, status.retweet_count, status.retweeted, \n",
    "              try_retweet(status,'retweeted_status'), \n",
    "              try_get(status.user, 'statuses_count'), \n",
    "              try_get(status.user, 'favourites_count'), \n",
    "              try_get(status.user, 'followers_count'),\n",
    "              try_get(status.user, 'description'),\n",
    "              try_get(status.user, 'location')]\n",
    "            \n",
    "            # write to csv\n",
    "            csvWriter.writerow(tweet)\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    "    \n",
    "    # tell us if there's an error\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    "\n",
    "twitter_stream = Stream(auth, MyListener())\n",
    "twitter_stream.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>lang</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_favorites_count</th>\n",
       "      <th>user_follower_count</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-24 21:24:41</td>\n",
       "      <td>RT @AcWgst: Reminds me of the fairytail~♡ Matt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'AcWgst']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love music, art, history, current events, WD...</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-24 21:24:41</td>\n",
       "      <td>ドラゴンスラッシュってスマホゲーらしいのだけれどスクリーンショットだけを見てるとほんとヴァニ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>県北</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-24 21:24:41</td>\n",
       "      <td>やられたでや\\r\\n石神さん状態w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>味楽一条通り店。時々有明 故に我はエロティカセブン</td>\n",
       "      <td>土田 みさと</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-24 21:24:41</td>\n",
       "      <td>#UKVOTY1D #MTVStars One Direction (MARO) Nicki...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[u'UKVOTY1D', u'MTVStars']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-24 21:24:41</td>\n",
       "      <td>RT @WhylmSingle: I WILL LOOK FOR YOU, I WILL F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'WhylmSingle']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronic music producer/vocalist, PR/AR mana...</td>\n",
       "      <td>Miami, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-11-24 21:24:41</td>\n",
       "      <td>RT @higeorgeshelley: If u guys vote enough ton...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'higeorgeshelley']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I wanna runaway...</td>\n",
       "      <td>my own little world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-11-24 21:24:41</td>\n",
       "      <td>I Been Sleeping On @gilliedakid He 🔥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'gilliedakid']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FMOI @quicktriggap Blessed Basketball Bigman S...</td>\n",
       "      <td>Philly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-11-24 21:24:41</td>\n",
       "      <td>RT @awwmyloueh: @izaynie93 I'm proud of you!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'awwmyloueh', u'izaynie93']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sometimes I add too little milk to my coffee a...</td>\n",
       "      <td>zquad ◡̈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-11-24 21:24:41</td>\n",
       "      <td>RT @CaronPeirson: @CleanDropMobile Let's clink...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[u'DigiBlogChat']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'CaronPeirson', u'CleanDropMobile']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CleanDrop  a mobile app for #foodies who deman...</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-11-24 21:24:41</td>\n",
       "      <td>RT @JosAntonioNez: Dentro de 1 mes todo el mun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'JosAntonioNez']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Del 97. Hermana de la Macarena. Auxiliar de En...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                               text place lang coordinates                    hashtags urls                          user_mentions  hashtag_count  url_count  mention_count  possibly_sensitive  favorite_count favorited  retweet_count retweeted retweeted_status  user_statuses_count  user_favorites_count  user_follower_count                                   user_description        user_location\n",
       "0  2015-11-24 21:24:41  RT @AcWgst: Reminds me of the fairytail~♡ Matt...   NaN   en         NaN                          []   []                            [u'AcWgst']              0          0              1                 NaN               0     False              0     False             True                  NaN                   NaN                  NaN  I love music, art, history, current events, WD...           California\n",
       "1  2015-11-24 21:24:41  ドラゴンスラッシュってスマホゲーらしいのだけれどスクリーンショットだけを見てるとほんとヴァニ...   NaN   ja         NaN                          []   []                                     []              0          0              0                 NaN               0     False              0     False              NaN                  NaN                   NaN                  NaN                                                NaN                   県北\n",
       "2  2015-11-24 21:24:41                                  やられたでや\\r\\n石神さん状態w   NaN   ja         NaN                          []   []                                     []              0          0              0                 NaN               0     False              0     False              NaN                  NaN                   NaN                  NaN                          味楽一条通り店。時々有明 故に我はエロティカセブン               土田 みさと\n",
       "3  2015-11-24 21:24:41  #UKVOTY1D #MTVStars One Direction (MARO) Nicki...   NaN   sl         NaN  [u'UKVOTY1D', u'MTVStars']   []                                     []              2          0              0                 NaN               0     False              0     False              NaN                  NaN                   NaN                  NaN                                                NaN                  NaN\n",
       "4  2015-11-24 21:24:41  RT @WhylmSingle: I WILL LOOK FOR YOU, I WILL F...   NaN   en         NaN                          []   []                       [u'WhylmSingle']              0          0              1                 NaN               0     False              0     False             True                  NaN                   NaN                  NaN  Electronic music producer/vocalist, PR/AR mana...            Miami, FL\n",
       "5  2015-11-24 21:24:41  RT @higeorgeshelley: If u guys vote enough ton...   NaN   en         NaN                          []   []                   [u'higeorgeshelley']              0          0              1                 NaN               0     False              0     False             True                  NaN                   NaN                  NaN                                 I wanna runaway...  my own little world\n",
       "6  2015-11-24 21:24:41              I Been Sleeping On @gilliedakid He 🔥   NaN   en         NaN                          []   []                       [u'gilliedakid']              0          0              1                 NaN               0     False              0     False              NaN                  NaN                   NaN                  NaN  FMOI @quicktriggap Blessed Basketball Bigman S...               Philly\n",
       "7  2015-11-24 21:24:41       RT @awwmyloueh: @izaynie93 I'm proud of you!   NaN   en         NaN                          []   []          [u'awwmyloueh', u'izaynie93']              0          0              2                 NaN               0     False              0     False             True                  NaN                   NaN                  NaN  sometimes I add too little milk to my coffee a...             zquad ◡̈\n",
       "8  2015-11-24 21:24:41  RT @CaronPeirson: @CleanDropMobile Let's clink...   NaN   en         NaN           [u'DigiBlogChat']   []  [u'CaronPeirson', u'CleanDropMobile']              1          0              2                 NaN               0     False              0     False             True                  NaN                   NaN                  NaN  CleanDrop  a mobile app for #foodies who deman...                  USA\n",
       "9  2015-11-24 21:24:41  RT @JosAntonioNez: Dentro de 1 mes todo el mun...   NaN   es         NaN                          []   []                     [u'JosAntonioNez']              0          0              1                 NaN               0     False              0     False             True                  NaN                   NaN                  NaN  Del 97. Hermana de la Macarena. Auxiliar de En...                  NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetdf_test=pd.read_csv(\"smallsample.csv\", names=[\"created_at\", \"text\", \"place\", \"lang\", \"coordinates\",\n",
    "                                       \"hashtags\", \"urls\", \"user_mentions\", \n",
    "                                       \"hashtag_count\", \"url_count\", \"mention_count\",\n",
    "                                       \"possibly_sensitive\", \n",
    "                                       \"favorite_count\", \"favorited\", \"retweet_count\", \"retweeted\",\n",
    "                                       \"retweeted_status\", \"user_statuses_count\", \"user_favorites_count\",\n",
    "                                       \"user_follower_count\", \"user_description\", \"user_location\"])\n",
    "tweetdf_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52766, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see however, the retweet count and favorite count are always 0. This is because we're using the live streaming API and as a result, we're scraping the tweets as they are tweeted. At this point, all the tweets have retweet count 0 and favorite count 0 since they were literally just posted! That is, unless the tweet posted is actually a retweet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just found this bug with retweet_count, looking into why this might be the case\n",
    "df_test = tweetdf_test[tweetdf_test['retweet_count'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting original retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function updates the way we use the tweepy streaming API. We first detect if the tweet we're looking at is actually a retweet of something. If so, we then get the original tweet and save that to our csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only save information for retweets\n",
    "\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "# get retweet status\n",
    "def try_retweet(status, attribute):\n",
    "    try:\n",
    "        if getattr(status, attribute):\n",
    "            return True\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "# get country status\n",
    "def try_country(status, attribute):\n",
    "    if getattr(status, attribute) != None:\n",
    "        place = getattr(status, attribute)\n",
    "        return place.country\n",
    "    return None\n",
    "\n",
    "# get city status\n",
    "def try_city(status, attribute):\n",
    "    if getattr(status, attribute) != None:\n",
    "        place = getattr(status, attribute)\n",
    "        return place.full_name\n",
    "    return None\n",
    "\n",
    "# function that tries to get attribute from object\n",
    "def try_get(status, attribute):\n",
    "    try:\n",
    "        return getattr(status, attribute).encode('utf-8')\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "# open csv file\n",
    "csvFile = open('originalsample.csv', 'a')\n",
    "\n",
    "# create csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "class MyListener(StreamListener):\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        try:\n",
    "            # if this represents a retweet\n",
    "            if try_retweet(status,'retweeted_status'):\n",
    "                status = status.retweeted_status\n",
    "                \n",
    "                # get and sanitize hashtags \n",
    "                hashtags = status.entities['hashtags']\n",
    "                hashtag_list = []\n",
    "                for el in hashtags:\n",
    "                    hashtag_list.append(el['text'])\n",
    "                hashtag_count = len(hashtag_list)\n",
    "\n",
    "                # get and sanitize urls\n",
    "                urls = status.entities['urls']\n",
    "                url_list = []\n",
    "                for el in urls:\n",
    "                    url_list.append(el['url'])\n",
    "                url_count = len(url_list)\n",
    "\n",
    "                # get and sanitize user_mentions\n",
    "                user_mentions = status.entities['user_mentions']\n",
    "                mention_list = []\n",
    "                for el in user_mentions:\n",
    "                    mention_list.append(el['screen_name'])\n",
    "                mention_count = len(mention_list)\n",
    "                \n",
    "                # save it all as a tweet\n",
    "                tweet = [status.id, status.created_at, try_country(status, 'place'), try_city(status, 'place'), status.text.encode('utf-8'), status.lang,\n",
    "                  hashtag_list, url_list, mention_list, \n",
    "                  hashtag_count, url_count, mention_count, \n",
    "                  try_get(status, 'possibly_sensitive'),\n",
    "                  status.favorite_count, status.favorited, status.retweet_count, status.retweeted, \n",
    "                  status.user.statuses_count, \n",
    "                  status.user.favourites_count, \n",
    "                  status.user.followers_count,\n",
    "                  try_get(status.user, 'description'),\n",
    "                  try_get(status.user, 'location'),\n",
    "                  try_get(status.user, 'time_zone')]\n",
    "            \n",
    "                # write to csv\n",
    "                csvWriter.writerow(tweet)\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    "    \n",
    "    # tell us if there's an error\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    "\n",
    "twitter_stream = Stream(auth, MyListener())\n",
    "twitter_stream.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_favorites_count</th>\n",
       "      <th>user_follower_count</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>669227044996124673</td>\n",
       "      <td>2015-11-24 18:52:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yo 💁🏼💟👌🏼 https://t.co/xLMaOl9QD4</td>\n",
       "      <td>und</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270</td>\n",
       "      <td>False</td>\n",
       "      <td>288</td>\n",
       "      <td>False</td>\n",
       "      <td>10726</td>\n",
       "      <td>18927</td>\n",
       "      <td>24429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yucatán, México</td>\n",
       "      <td>Mexico City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>669328402453626880</td>\n",
       "      <td>2015-11-25 01:35:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>読者が生産者に会いに行く!『北海道食べる通信』初の読者ツアー開催 – 北海道ファンマガジン ...</td>\n",
       "      <td>ja</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'https://t.co/w4GkSYLhoz']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>10176</td>\n",
       "      <td>241</td>\n",
       "      <td>1783</td>\n",
       "      <td>手稲駅南口直結徒歩１分　ハートビル法認定バリアフリーホテル　札幌市福祉のまちづくり条例適合ホ...</td>\n",
       "      <td>北海道札幌市手稲区手稲本町1条4丁目1番５号</td>\n",
       "      <td>Sapporo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>669335707505201152</td>\n",
       "      <td>2015-11-25 02:04:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not 1 shot, not 2 but 16. 16 tax payer purchas...</td>\n",
       "      <td>en</td>\n",
       "      <td>[u'LaquanMcDonald', u'sickofthesehashtags']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>15349</td>\n",
       "      <td>1590</td>\n",
       "      <td>69865</td>\n",
       "      <td>Sideways Slipper, ALEKESAM</td>\n",
       "      <td>The Universe</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>668550084976578560</td>\n",
       "      <td>2015-11-22 22:02:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#comeeeheree @DooleyFunnyAf !! Had to get yo a...</td>\n",
       "      <td>en</td>\n",
       "      <td>[u'comeeeheree']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'DooleyFunnyAf']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>11124</td>\n",
       "      <td>15210</td>\n",
       "      <td>4085</td>\n",
       "      <td>$quad Original | https://soundcloud.com/vanteb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>669304504513380352</td>\n",
       "      <td>2015-11-25 00:00:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best #Thanksgiving memory? @KnucklePuckIL shar...</td>\n",
       "      <td>en</td>\n",
       "      <td>[u'Thanksgiving']</td>\n",
       "      <td>[u'https://t.co/IYC1jEOTeC']</td>\n",
       "      <td>[u'KnucklePuckIL']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>52246</td>\n",
       "      <td>4509</td>\n",
       "      <td>526915</td>\n",
       "      <td>The nation’s leading voice on underground, alt...</td>\n",
       "      <td>Cleveland, Ohio</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>669178757417009152</td>\n",
       "      <td>2015-11-24 15:40:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Muhammad kenapa handsome sangat 😍😂 https://t...</td>\n",
       "      <td>in</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "      <td>False</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>58643</td>\n",
       "      <td>8317</td>\n",
       "      <td>733</td>\n",
       "      <td>spread positivity ✨</td>\n",
       "      <td>MY</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>669348536081850369</td>\n",
       "      <td>2015-11-25 02:55:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rt for 5sos #MTVStars 5 Seconds of Summer</td>\n",
       "      <td>en</td>\n",
       "      <td>[u'MTVStars']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>9816</td>\n",
       "      <td>3</td>\n",
       "      <td>3299</td>\n",
       "      <td>appreciating Michael mostly *ଘ(੭*ˊᵕˋ)੭* ੈ✩‧₊˚ ...</td>\n",
       "      <td>(Liv • Blain• Ant)</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>669335559425417216</td>\n",
       "      <td>2015-11-25 02:03:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Why didn't you do your homework over the holi...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283</td>\n",
       "      <td>False</td>\n",
       "      <td>218</td>\n",
       "      <td>False</td>\n",
       "      <td>53293</td>\n",
       "      <td>341</td>\n",
       "      <td>476765</td>\n",
       "      <td>just stahp. \\r\\n\\r\\nyou probably just ignore m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>669339114974478336</td>\n",
       "      <td>2015-11-25 02:17:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I think one of my favorite feelings is laughin...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>10140</td>\n",
       "      <td>6619</td>\n",
       "      <td>953</td>\n",
       "      <td>⊱✿LIVE. .Like there's no midnight! ✿⊰ idfwu, t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>669348858418192384</td>\n",
       "      <td>2015-11-25 02:56:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>하루치하\\r\\n같이 팝시다\\r\\n#프로듀서_트친소 https://t.co/0ARAt...</td>\n",
       "      <td>ko</td>\n",
       "      <td>[u'\\ud504\\ub85c\\ub4c0\\uc11c_\\ud2b8\\uce5c\\uc18c']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>22768</td>\n",
       "      <td>1295</td>\n",
       "      <td>159</td>\n",
       "      <td>아이마스와 하루치하 파는 잉여 유하치 / 쿄애니, 중력폭포, 디즈니 픽사도 파요!!...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>667108285628203011</td>\n",
       "      <td>2015-11-18 22:33:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michael Kors https://t.co/62WBkX7pXT</td>\n",
       "      <td>und</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1797</td>\n",
       "      <td>False</td>\n",
       "      <td>798</td>\n",
       "      <td>False</td>\n",
       "      <td>4975</td>\n",
       "      <td>1622</td>\n",
       "      <td>1375064</td>\n",
       "      <td>♥ Whats on your bucket list? ♥ #Contact✉: that...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>668717375622021120</td>\n",
       "      <td>2015-11-23 09:07:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Me: he told me to calm down\\r\\n\\r\\n911: ma'am ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>False</td>\n",
       "      <td>76</td>\n",
       "      <td>False</td>\n",
       "      <td>63011</td>\n",
       "      <td>76098</td>\n",
       "      <td>10895</td>\n",
       "      <td>wife of 1 mother of 6 https://twitter.com/sear...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>669344114698244096</td>\n",
       "      <td>2015-11-25 02:37:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i pray 2016 is good to me.</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2581</td>\n",
       "      <td>False</td>\n",
       "      <td>1919</td>\n",
       "      <td>False</td>\n",
       "      <td>47876</td>\n",
       "      <td>4363</td>\n",
       "      <td>2152466</td>\n",
       "      <td>Everything was David Karp and nothing hurt. *P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>665688360434794496</td>\n",
       "      <td>2015-11-15 00:30:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jesushalonso @Isulyfitz nos encanta consentir...</td>\n",
       "      <td>es</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'jesushalonso', u'Isulyfitz']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>4434</td>\n",
       "      <td>1949</td>\n",
       "      <td>58922</td>\n",
       "      <td>Somos la cadena de comida rápida más grande de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexico City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>669341091573829632</td>\n",
       "      <td>2015-11-25 02:25:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200RT : 「劇場版『ガルパン』を観に行ったら不快な残酷ホラー映画の予告を流された」とア...</td>\n",
       "      <td>ja</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'https://t.co/R4MWf7R7wT']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>255855</td>\n",
       "      <td>88</td>\n",
       "      <td>428708</td>\n",
       "      <td>オレ的ゲーム速報のツイッターです。（＾ω＾　Youtubeちゃんねるはこちら→https:/...</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at country city                                               text lang                                          hashtags                          urls                    user_mentions  hashtag_count  url_count  mention_count  possibly_sensitive  favorite_count favorited  retweet_count retweeted  user_statuses_count  user_favorites_count  user_follower_count                                   user_description           user_location  \\\n",
       "0   669227044996124673  2015-11-24 18:52:15     NaN  NaN              Yo 💁🏼💟👌🏼 https://t.co/xLMaOl9QD4  und                                                []                            []                               []              0          0              0                 NaN             270     False            288     False                10726                 18927                24429                                                NaN         Yucatán, México   \n",
       "1   669328402453626880  2015-11-25 01:35:01     NaN  NaN  読者が生産者に会いに行く!『北海道食べる通信』初の読者ツアー開催 – 北海道ファンマガジン ...   ja                                                []  [u'https://t.co/w4GkSYLhoz']                               []              0          1              0                 NaN               1     False              1     False                10176                   241                 1783  手稲駅南口直結徒歩１分　ハートビル法認定バリアフリーホテル　札幌市福祉のまちづくり条例適合ホ...  北海道札幌市手稲区手稲本町1条4丁目1番５号   \n",
       "2   669335707505201152  2015-11-25 02:04:02     NaN  NaN  Not 1 shot, not 2 but 16. 16 tax payer purchas...   en       [u'LaquanMcDonald', u'sickofthesehashtags']                            []                               []              2          0              0                 NaN              25     False             23     False                15349                  1590                69865                         Sideways Slipper, ALEKESAM            The Universe   \n",
       "3   668550084976578560  2015-11-22 22:02:15     NaN  NaN  #comeeeheree @DooleyFunnyAf !! Had to get yo a...   en                                  [u'comeeeheree']                            []               [u'DooleyFunnyAf']              1          0              1                 NaN              24     False             28     False                11124                 15210                 4085  $quad Original | https://soundcloud.com/vanteb...                     NaN   \n",
       "4   669304504513380352  2015-11-25 00:00:03     NaN  NaN  Best #Thanksgiving memory? @KnucklePuckIL shar...   en                                 [u'Thanksgiving']  [u'https://t.co/IYC1jEOTeC']               [u'KnucklePuckIL']              1          1              1                 NaN             158     False             33     False                52246                  4509               526915  The nation’s leading voice on underground, alt...         Cleveland, Ohio   \n",
       "5   669178757417009152  2015-11-24 15:40:23     NaN  NaN  Muhammad kenapa handsome sangat 😍😂 https://t...   in                                                []                            []                               []              0          0              0                 NaN              91     False            173     False                58643                  8317                  733                                spread positivity ✨                      MY   \n",
       "6   669348536081850369  2015-11-25 02:55:01     NaN  NaN          rt for 5sos #MTVStars 5 Seconds of Summer   en                                     [u'MTVStars']                            []                               []              1          0              0                 NaN               3     False             21     False                 9816                     3                 3299  appreciating Michael mostly *ଘ(੭*ˊᵕˋ)੭* ੈ✩‧₊˚ ...     (Liv • Blain• Ant)    \n",
       "7   669335559425417216  2015-11-25 02:03:27     NaN  NaN  \"Why didn't you do your homework over the holi...   en                                                []                            []                               []              0          0              0                 NaN             283     False            218     False                53293                   341               476765  just stahp. \\r\\n\\r\\nyou probably just ignore m...                     NaN   \n",
       "8   669339114974478336  2015-11-25 02:17:35     NaN  NaN  I think one of my favorite feelings is laughin...   en                                                []                            []                               []              0          0              0                 NaN               5     False              1     False                10140                  6619                  953  ⊱✿LIVE. .Like there's no midnight! ✿⊰ idfwu, t...                     NaN   \n",
       "9   669348858418192384  2015-11-25 02:56:18     NaN  NaN  하루치하\\r\\n같이 팝시다\\r\\n#프로듀서_트친소 https://t.co/0ARAt...   ko  [u'\\ud504\\ub85c\\ub4c0\\uc11c_\\ud2b8\\uce5c\\uc18c']                            []                               []              1          0              0                 NaN               0     False              7     False                22768                  1295                  159  아이마스와 하루치하 파는 잉여 유하치 / 쿄애니, 중력폭포, 디즈니 픽사도 파요!!...                     NaN   \n",
       "10  667108285628203011  2015-11-18 22:33:04     NaN  NaN               Michael Kors https://t.co/62WBkX7pXT  und                                                []                            []                               []              0          0              0                 NaN            1797     False            798     False                 4975                  1622              1375064  ♥ Whats on your bucket list? ♥ #Contact✉: that...                     NaN   \n",
       "11  668717375622021120  2015-11-23 09:07:01     NaN  NaN  Me: he told me to calm down\\r\\n\\r\\n911: ma'am ...   en                                                []                            []                               []              0          0              0                 NaN             118     False             76     False                63011                 76098                10895  wife of 1 mother of 6 https://twitter.com/sear...                     NaN   \n",
       "12  669344114698244096  2015-11-25 02:37:27     NaN  NaN                         i pray 2016 is good to me.   en                                                []                            []                               []              0          0              0                 NaN            2581     False           1919     False                47876                  4363              2152466  Everything was David Karp and nothing hurt. *P...                     NaN   \n",
       "13  665688360434794496  2015-11-15 00:30:47     NaN  NaN  @jesushalonso @Isulyfitz nos encanta consentir...   es                                                []                            []  [u'jesushalonso', u'Isulyfitz']              0          0              2                 NaN              68     False             25     False                 4434                  1949                58922  Somos la cadena de comida rápida más grande de...                     NaN   \n",
       "14  669341091573829632  2015-11-25 02:25:26     NaN  NaN  200RT : 「劇場版『ガルパン』を観に行ったら不快な残酷ホラー映画の予告を流された」とア...   ja                                                []  [u'https://t.co/R4MWf7R7wT']                               []              0          1              0                 NaN              61     False             96     False               255855                    88               428708  オレ的ゲーム速報のツイッターです。（＾ω＾　Youtubeちゃんねるはこちら→https:/...                   Japan   \n",
       "\n",
       "                 user_timezone  \n",
       "0                  Mexico City  \n",
       "1                      Sapporo  \n",
       "2   Pacific Time (US & Canada)  \n",
       "3   Eastern Time (US & Canada)  \n",
       "4   Eastern Time (US & Canada)  \n",
       "5                 Kuala Lumpur  \n",
       "6   Eastern Time (US & Canada)  \n",
       "7   Eastern Time (US & Canada)  \n",
       "8                          NaN  \n",
       "9   Pacific Time (US & Canada)  \n",
       "10                   New Delhi  \n",
       "11  Pacific Time (US & Canada)  \n",
       "12  Eastern Time (US & Canada)  \n",
       "13                 Mexico City  \n",
       "14                       Tokyo  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetdf=pd.read_csv(\"originalsample.csv\", names=[\"id\", \"created_at\", \"country\", \"city\", \"text\", \"lang\",\n",
    "                                       \"hashtags\", \"urls\", \"user_mentions\", \n",
    "                                       \"hashtag_count\", \"url_count\", \"mention_count\",\n",
    "                                       \"possibly_sensitive\", \n",
    "                                       \"favorite_count\", \"favorited\", \"retweet_count\", \"retweeted\",\n",
    "                                       \"user_statuses_count\", \"user_favorites_count\",\n",
    "                                       \"user_follower_count\", \"user_description\", \"user_location\", \"user_timezone\"])\n",
    "tweetdf.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114509, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter for language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_filtered = tweetdf[tweetdf['lang'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57079, 23)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter for timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# don't get timezone location so not sure this is possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popularity formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popularity = [retweets + favs for retweets, favs in zip(df_filtered.retweet_count, df_filtered.favorite_count)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add popularity column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eden/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df_filtered['popularity'] = popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57079, 24)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_favorites_count</th>\n",
       "      <th>user_follower_count</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>669335707505201152</td>\n",
       "      <td>2015-11-25 02:04:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not 1 shot, not 2 but 16. 16 tax payer purchas...</td>\n",
       "      <td>en</td>\n",
       "      <td>[u'LaquanMcDonald', u'sickofthesehashtags']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>15349</td>\n",
       "      <td>1590</td>\n",
       "      <td>69865</td>\n",
       "      <td>Sideways Slipper, ALEKESAM</td>\n",
       "      <td>The Universe</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>668550084976578560</td>\n",
       "      <td>2015-11-22 22:02:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#comeeeheree @DooleyFunnyAf !! Had to get yo a...</td>\n",
       "      <td>en</td>\n",
       "      <td>[u'comeeeheree']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[u'DooleyFunnyAf']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>11124</td>\n",
       "      <td>15210</td>\n",
       "      <td>4085</td>\n",
       "      <td>$quad Original | https://soundcloud.com/vanteb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>669304504513380352</td>\n",
       "      <td>2015-11-25 00:00:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best #Thanksgiving memory? @KnucklePuckIL shar...</td>\n",
       "      <td>en</td>\n",
       "      <td>[u'Thanksgiving']</td>\n",
       "      <td>[u'https://t.co/IYC1jEOTeC']</td>\n",
       "      <td>[u'KnucklePuckIL']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>52246</td>\n",
       "      <td>4509</td>\n",
       "      <td>526915</td>\n",
       "      <td>The nation’s leading voice on underground, alt...</td>\n",
       "      <td>Cleveland, Ohio</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>669348536081850369</td>\n",
       "      <td>2015-11-25 02:55:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rt for 5sos #MTVStars 5 Seconds of Summer</td>\n",
       "      <td>en</td>\n",
       "      <td>[u'MTVStars']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>9816</td>\n",
       "      <td>3</td>\n",
       "      <td>3299</td>\n",
       "      <td>appreciating Michael mostly *ଘ(੭*ˊᵕˋ)੭* ੈ✩‧₊˚ ...</td>\n",
       "      <td>(Liv • Blain• Ant)</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>669335559425417216</td>\n",
       "      <td>2015-11-25 02:03:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Why didn't you do your homework over the holi...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283</td>\n",
       "      <td>False</td>\n",
       "      <td>218</td>\n",
       "      <td>False</td>\n",
       "      <td>53293</td>\n",
       "      <td>341</td>\n",
       "      <td>476765</td>\n",
       "      <td>just stahp. \\r\\n\\r\\nyou probably just ignore m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           created_at country city                                               text lang                                     hashtags                          urls       user_mentions  hashtag_count  url_count  mention_count  possibly_sensitive  favorite_count favorited  retweet_count retweeted  user_statuses_count  user_favorites_count  user_follower_count                                   user_description        user_location               user_timezone  popularity\n",
       "2  669335707505201152  2015-11-25 02:04:02     NaN  NaN  Not 1 shot, not 2 but 16. 16 tax payer purchas...   en  [u'LaquanMcDonald', u'sickofthesehashtags']                            []                  []              2          0              0                 NaN              25     False             23     False                15349                  1590                69865                         Sideways Slipper, ALEKESAM         The Universe  Pacific Time (US & Canada)          48\n",
       "3  668550084976578560  2015-11-22 22:02:15     NaN  NaN  #comeeeheree @DooleyFunnyAf !! Had to get yo a...   en                             [u'comeeeheree']                            []  [u'DooleyFunnyAf']              1          0              1                 NaN              24     False             28     False                11124                 15210                 4085  $quad Original | https://soundcloud.com/vanteb...                  NaN  Eastern Time (US & Canada)          52\n",
       "4  669304504513380352  2015-11-25 00:00:03     NaN  NaN  Best #Thanksgiving memory? @KnucklePuckIL shar...   en                            [u'Thanksgiving']  [u'https://t.co/IYC1jEOTeC']  [u'KnucklePuckIL']              1          1              1                 NaN             158     False             33     False                52246                  4509               526915  The nation’s leading voice on underground, alt...      Cleveland, Ohio  Eastern Time (US & Canada)         191\n",
       "6  669348536081850369  2015-11-25 02:55:01     NaN  NaN          rt for 5sos #MTVStars 5 Seconds of Summer   en                                [u'MTVStars']                            []                  []              1          0              0                 NaN               3     False             21     False                 9816                     3                 3299  appreciating Michael mostly *ଘ(੭*ˊᵕˋ)੭* ੈ✩‧₊˚ ...  (Liv • Blain• Ant)   Eastern Time (US & Canada)          24\n",
       "7  669335559425417216  2015-11-25 02:03:27     NaN  NaN  \"Why didn't you do your homework over the holi...   en                                           []                            []                  []              0          0              0                 NaN             283     False            218     False                53293                   341               476765  just stahp. \\r\\n\\r\\nyou probably just ignore m...                  NaN  Eastern Time (US & Canada)         501"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scraping the tweets from the Twitter API, we can use that data to build a feature list that we use to predict how popular an individual tweet is, measured by a composite score based on the amount of retweets and hearts. We will also use metadata to help us analyze trends in the data, for example if there is a correlation between time of day and retweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yuqi Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 hashtags (ranking hashtags by most popular) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between length of tweet and popularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between presence of image and popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between presence of links and popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between user mentions and popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation for number of retweets and hearts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zahra Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between time of day and tweet popularity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The distribution of hearts & retweets over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User's followers correlated with popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's popular within the 10 most populous cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's most popular within each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trending tweets and trending lists affecting virality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining positive/negative words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#notes: Unicode in texts (probably emoticons? should we find a way to categorize those?)\n",
    "#df_filtered['text']\n",
    "\n",
    "#load dicts into lookup, map words to pos or neg value\n",
    "#current dict: not sure where it's from?\n",
    "lookup = {}\n",
    "with open('positive.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        word = line[:-1]\n",
    "        lookup[word] = 1\n",
    "with open('negative.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        word = line[:-1]\n",
    "        lookup[word] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#text = reduce(lambda x,y: x+y, df_filtered['text'].apply(lambda x: [x])) # list of strings, functionally identical to df_filtered['text']\n",
    "tweetstext = reduce(lambda x,y: x + '\\n' + y, df_filtered['text']) # string of concatenated texts, all\n",
    "# filter out stop words, etc\n",
    "tokens = nltk.word_tokenize(tweetstext.decode('utf-8','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 359792\n",
      "1337 of 359792 words in lookup.\n",
      "[u'uplifting', u'controversy', u'golden', u'catchy', u'inevitable', u'wrong', u'sickening', u'fit', u'master', u'shambles']\n",
      "[u'MattFontana83', u'//t.co/gvJiHUEX3T', u'JOHNNY', u'1,800', u'Poetry', u'//t.co/zcpGKi6dNH', u'BLACK/SILVER', u'hanging', u'woody', u'16:30:30']\n"
     ]
    }
   ],
   "source": [
    "print \"Number of tokens:\", len(tokens)\n",
    "fdist = nltk.FreqDist(tokens)\n",
    "fdist.most_common(50)\n",
    "inlookup = []\n",
    "notfound = []\n",
    "for key in fdist.keys():\n",
    "    if key in lookup.keys():\n",
    "        inlookup.append(key)\n",
    "    else:\n",
    "        notfound.append(key)\n",
    "print \"{} of {} words in lookup.\".format(len(inlookup), len(tokens))\n",
    "print inlookup[:10]\n",
    "print notfound[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(RT, @, AcWgst), (@, AcWgst, :), (AcWgst, :, ...\n",
       "4    [(RT, @, WhylmSingle), (@, WhylmSingle, :), (W...\n",
       "5    [(RT, @, higeorgeshelley), (@, higeorgeshelley...\n",
       "6    [(I, Been, Sleeping), (Been, Sleeping, On), (S...\n",
       "7    [(RT, @, awwmyloueh), (@, awwmyloueh, :), (aww...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = df_filtered['text'].apply(lambda x: list(nltk.bigrams(nltk.word_tokenize(x.decode('utf-8','ignore')))))\n",
    "trigrams = df_filtered['text'].apply(lambda x: list(nltk.trigrams(nltk.word_tokenize(x.decode('utf-8','ignore')))))\n",
    "trigrams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length of post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controversy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-11-14 05:41:34 RT @_MinaDaFly1D: Say no! Say no of the violence in the world! Go to love more 🙏🏻😱❤️ #PrayForJapan\n",
      "2015-11-14 05:41:34 RT @GEO7GE: Seriously can't believe this has all happened in a day. #PrayForParis #PrayforBeirut #PrayforJapan https://t.co/CYCM2eViSI\n",
      "2015-11-14 05:41:34 RT @Friendstagram: All we can do is PRAY 🙏🏼🌏\n",
      "\n",
      "#PrayForParis \n",
      "#PrayForJapan\n",
      "#PrayForLebanon \n",
      "#PrayForBaghdad \n",
      "#PrayForMexico https://t.co/K2…\n",
      "2015-11-14 05:41:34 RT @CIothesPorn: My prayers go out to everyone 🙏🏼🙏🏼\n",
      "#PrayForParis \n",
      "#PrayForJapan \n",
      "#PrayForLebanon \n",
      "#PrayForBaghdad \n",
      "#PrayForMexico https://…\n",
      "2015-11-14 05:41:34 RT @loukeypookey: So sad that this all happened :(\n",
      "#PrayForJapan\n",
      "#PrayForLebanon\n",
      "#PrayForBaghdad\n",
      "#PrayForMexico\n",
      "#PrayForParis https://t.co/…\n",
      "2015-11-14 05:41:34 RT @justinbieburnt: Justin Bieber and his beliebers praying for Paris and Japan. #PrayForParis #PrayForJapan https://t.co/b2yNFYUSwS\n",
      "2015-11-14 05:41:33 RT @zaynbaabe: Justin's album will still be there tomorrow but some lives wont, this is disgusting.\n",
      "\n",
      "#PrayForJapan\n",
      "#PrayersForParis https:/…\n",
      "2015-11-14 05:41:33 For anyone involved, you're in my thoughts &amp; prayers #PrayForJapan\n",
      "2015-11-14 05:41:33 RT @cheastain: In one day ? Pray for them . \n",
      "\n",
      "#PrayforParis \n",
      "#PrayforJapan  \n",
      "#PrayForBagdad \n",
      "#PrayForBeirut \n",
      "#PrayForMexico https://t.co/0j…\n",
      "2015-11-14 05:41:33 RT @Friendstagram: All we can do is PRAY 🙏🏼🌏\n",
      "\n",
      "#PrayForParis \n",
      "#PrayForJapan\n",
      "#PrayForLebanon \n",
      "#PrayForBaghdad \n",
      "#PrayForMexico https://t.co/K2…\n",
      "2015-11-14 05:41:33 RT @thereaIbanksy: Friday the 13th hasn't been easy on the world 🙏\n",
      "\n",
      "#PrayForParis\n",
      "#PrayForJapan\n",
      "#PrayForMexico\n",
      "#PrayForLebanon https://t.co…\n",
      "2015-11-14 05:41:33 RT @astronautbarnes: #PrayforJapan - earthquake\n",
      "#PrayforParis - got attacked\n",
      "#PrayforLebanon - got attacked \n",
      "#PrayforBeirut - got attacked\n",
      "…\n",
      "2015-11-14 05:41:33 RT @lordoftheluke: #PrayforParis\n",
      "#PrayforJapan\n",
      "#PrayForBeirut\n",
      "#PrayforBaghdad\n",
      "#PrayforMexico\n",
      "#PrayForLebanon\n",
      "\n",
      "All in one day, 24 hours, 115…\n",
      "2015-11-14 05:41:33 RT @cheonsa_ia: wake up to all of this 😱\n",
      "#PrayforParis \n",
      "#PrayforJapan  \n",
      "#PrayForBagdad \n",
      "#PrayForBeirut \n",
      "#PrayForMexico \n",
      "🙏❤ https://t.co/9S6…\n",
      "2015-11-14 05:41:33 RT @BrittanyMDonald: #ParisAttacks #Prayers4Paris #Pray4theWorld #PrayForJapan retweet if you are praying for world peace and the end of se…\n",
      "2015-11-14 05:41:32 RT @EXOffical: Take your time to\n",
      "#PrayForParis\n",
      "#PrayForJapan\n",
      "#PrayForMexico\n",
      "#PrayForLebanon \n",
      "\n",
      "Please be safe! 🙏🏼\n",
      "2015-11-14 05:41:32 RT @nabilakamalia13: my prayers are with you, I may not know you but we're living under the same sky 🌎💔🙏 #PrayForJapan #PrayForParis and pl…\n",
      "2015-11-14 05:41:32 RT @thereaIbanksy: Friday the 13th hasn't been easy on the world 🙏\n",
      "\n",
      "#PrayForParis\n",
      "#PrayForJapan\n",
      "#PrayForMexico\n",
      "#PrayForLebanon https://t.co…\n",
      "2015-11-14 05:41:32 RT @teenagernotes: Extremely true \n",
      "#PrayForParis \n",
      "#PrayForBaghdad \n",
      "#PrayforBeirut \n",
      "#PrayForIraq\n",
      "#PrayForJapan \n",
      "#PrayForMexico https://t.co/…\n",
      "2015-11-14 05:41:32 RT @SadHappyAmazing: Friday the 13th hasn't been easy on the world 🙏\n",
      "\n",
      "#PrayForParis\n",
      "#PrayForJapan\n",
      "#PrayForMexico\n",
      "#PrayForLebanon https://t.…\n"
     ]
    },
    {
     "ename": "TweepError",
     "evalue": "{\"errors\":[{\"message\":\"Rate limit exceeded\",\"code\":88}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-386b69e99b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcsvWriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"#PrayForJapan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m                           \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m                           \u001b[0msince_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2015\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcsvWriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eden/anaconda/lib/python2.7/site-packages/tweepy/cursor.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eden/anaconda/lib/python2.7/site-packages/tweepy/cursor.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eden/anaconda/lib/python2.7/site-packages/tweepy/binder.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;31m# Set pagination mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eden/anaconda/lib/python2.7/site-packages/tweepy/binder.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Twitter error response: status code = %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# Parse the response payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTweepError\u001b[0m: {\"errors\":[{\"message\":\"Rate limit exceeded\",\"code\":88}]}"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# another example with Cursor get all tweets with a certain hashtag and a certain time frame within past week \n",
    "csvFile = open('tweets.csv', 'a')\n",
    "#Use csv Writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,q=\"#PrayForJapan\",count=1,\\\n",
    "                           lang=\"en\",\\\n",
    "                           since_id=2015-11-13).items():\n",
    "    print tweet.created_at, tweet.text\n",
    "    csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
